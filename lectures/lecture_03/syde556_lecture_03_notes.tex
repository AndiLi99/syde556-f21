% !TeX spellcheck = en_GB
\documentclass[10pt,letterpaper,oneside]{article}
\input{../syde556_lecture_notes_preamble}

\date{January 14 \& 16, 2020}
\title{SYDE 556/750 \\ Simulating Neurobiological Systems \\ Lecture 3: Representation}


\begin{document}

\MakeTitle{\textbf{Accompanying Readings: Chapter 2 of Neural Engineering}}

\section{Introduction}

\Note{In the last lecture, we had a look at a the Leaky Integrate-and-Fire neuron model as an approximation of the behaviour of biological neurons. In this lecture, we discuss a theory of neural representation. Together with our knowledge about neural responses this forms a theory of what \enquote{the neural code} may be.}

In order to survive in natural environments, animals must build representations of their surroundings. This includes the physical properties of objects in their vicinity, such as \emph{velocity}, \emph{location}, \emph{colour}, etc., but also non-physical properties such as whether an object is \emph{edible}, or \emph{dangerous}. Of course such representations are not only limited to external objects, but may carry information about the own body (e.g., \enquote{proprioception}, configuration of limbs; location in space), up to abstract thought and emotions.

For now, and mostly because it is the easiest to reason about, we shall restrict ourselves to relatively low-level representations of sensory information. In this case, representation is directly evident from correlation between some external quantity and neural activity.  We saw examples of such representations in the first lecture. For example, in the classical Hubel and Wiesel experiment (\YouTube{KE952yueVLA}, \cite{hubel1959receptive}), individual neural activity is correlated with the location and orientation of a bar of light (an \enquote{edge}) within the visual field. Similarly, in the case of place cells (\YouTube{lfNVv0A8QvI}), neural activity is correlated with the location of the animal in space.

A central claim of the Neural Engineering Framework (NEF) is that values $\vec x$ -- e.g., the physical quantities mentioned above -- are represented in the neural activity $\vec a$ of \emph{groups} of neurons. Furthermore, we claim that there is a non-linear encoding process that translates a value into a neural activity pattern, and a linear decoding process that estimates the represented value from neural activity patterns.

\begin{mdframed}
\textbf{NEF Principle 1 -- Representation}\\
\emph{Groups} (\enquote{populations}, or \enquote{ensembles}) of neurons \emph{represent} values via nonlinear encoding and linear decoding.
\end{mdframed}

We will first discuss the encoding and decoding of values in a more abstract sense, and then propose a particular mechanism by which values are encoded in the NEF. Since \emph{encoding} only takes us half of the way, we then discuss \emph{decoding}, in particular in the presence of noise in the neural activities.

\Notation{Scalars, functions are italic letters ($d$, $n$, $N$, $f$,\textellipsis), vectors are bold lowercase letters ($\vec a, \vec e$, $\vec x$), matrices are bold uppercase letters ($\mat A$), sets are double-struck uppercase letters ($\mathbb{R}$, $\mathbb{N}$). $\mathbb{A} \rightarrow \mathbb{B}$ denotes a function mapping from the domain $\mathbb{A}$ onto a codomain $\mathbb{B}$.
\allowdisplaybreaks
\begin{align*}
	d &\in \mathbb{N} &&~ \text{Dimensionality of the value represented by a neuron population} \\
	n &\in \mathbb{N} &&~ \text{Number of neurons in a neuron population} \\
	N &\in \mathbb{N} &&~ \text{Number of samples}\\
	\langle \vec x, \vec y \rangle &: \mathbb{R}^k \times \mathbb{R}^k \rightarrow \mathbb{R} &&~ \text{Dot product between two $k$-dimensional vectors $\vec x$ and $\vec y$} \\Â¸
	G[J]  &: \mathbb{R} \rightarrow \mathbb{R}^+  &&~ \text{Neural response for an input current $J$ (\emph{response curve})} \\
	a_i (\vec x) &: \mathbb{R}^d \rightarrow \mathbb{R}^+ &&~ \text{Neural response of neuron $i$ in a neural population (\emph{tuning curve})}\\
	\vec a(\vec x) &: \mathbb{R}^d \rightarrow (\mathbb{R}^+)^n &&~ \text{Neural response of all neurons in a neural population}\\
	{\vec e}_i &\in \mathbb{R}^d &&~ \text{Encoding vector, or \enquote{preferred direction}, of neuron $i$ in a population}\\
	\alpha_i &\in \mathbb{R} &&~ \text{The $i$-th neuron's gain factor}\\
	J^\mathrm{bias}_i &\in \mathbb{R} &&~ \text{The $i$-th neuron's bias current}\\
	\vec x_j &\in \mathbb{R}^d &&~ \text{$j$-th (out of $N$) input sample} \\
	{\hat{\vec x}}_j &\in \mathbb{R}^{d} &&~ \text{Decoded $j$-th input sample} \\
	\mat X &\in \mathbb{R}^{d \times N} &&~ \text{Matrix of input samples}\\
	\mat A &\in \mathbb{R}^{n \times N} &&~ \text{Matrix of sampled population activities}\\
	\vec d_i &\in \mathbb{R}^{n} &&~ \text{Decoding vector for the $i$-th neuron in the population} \hspace{0.25cm}\\
	\mat D &\in \mathbb{R}^{d \times n} &&~ \text{Decoding matrix}
\end{align*}\vspace{-0.75cm}}

\section{Codes: Representing Information}

Human societies have relied on exchanging coded information for millennia. Apart from written and spoken language themselves, examples of such codes include flag semaphores, or Morse code \cite{2009itur}.

These codes have in common that there is some kind of \emph{encoding} process that turns an original message $\vec x$ into a coded message $\vec a$, and a \emph{decoding} process that reconstructs $\vec x$ from $\vec a$. If $\vec x$ can be perfectly reconstructed, this is called \emph{lossless coding}, otherwise \emph{lossy coding}.

\subsection{Lossless Codes}

In the case of a lossless code, there exists an encoding function $f$, as well as its inverse $f^{-1}$. It holds
\begin{align*}
	\vec a &= f(\vec x) \,, && \text{Encoding} \\
	\vec x &= f^{-1}(\vec a) = g(f(\vec x)) \,. && \text{Decoding} 
\end{align*}

\paragraph{Morse Code} Morse code is an example of such a lossless coding scheme. A function $f$ takes a character sequence and turns it into valid Morse code, consisting of dots~($\cdot$) and dashes~($-$):
\begin{align*}
	\begin{aligned}
	f&: \mathcal{S}(\{\mathtt{A}, \ldots, \mathtt{Z}, \text{\textvisiblespace}\}) \rightarrow \mathbb{M} \,. \\
	f^{-1} &: \mathbb{M} \rightarrow \mathcal{S}(\{\mathtt{A}, \ldots, \mathtt{Z}, \text{\textvisiblespace}\}) \,.
	\end{aligned} &&\quad \text{where } \mathbb{M} \subset \mathcal{S}(\{\cdot, -\}) \text{ is the set of valid Morse messages}
\end{align*}
Here, $\mathcal{S}$ denotes the set of all sequences consisting of the given elements (i.e., the union over all Cartesian powers).

\paragraph{Binary numbers}
As a more concrete example, let's consider an $n$-bit binary coding of natural numbers. Here, our coded message $\vec a = (a_0, a_1, a_2, a_3, \ldots, a_{n - 1})$ where $a_i \in \{0, 1\}$, while our original value $x$ is a natural number between zero and $2^n - 1$.

We can write down the encoding function $f$
\begin{align*}
	a_i &= \big(f(x)\big)_i = \begin{cases}
		1 & \text{if } x - 2^i \left\lfloor \frac{x}{2^i} \right\rfloor > 2^{i - 1} \,,\\
		0 & \text{otherwise} \,.
	\end{cases}
\end{align*}
This function is nonlinear -- we cannot write it as a matrix-vector product. The decoding function $f^{-1}$ is given as
\begin{align*}
	x &= f^{-1}(\vec a) = \sum_{i=0}^{n -1} 2^i a_i \,.
\end{align*}
This function is \emph{linear} in $\vec a$ because we can write it as a matrix-vector product
\begin{align*}
x = f^{-1}(\vec a) = {\mat F} \vec a = \begin{pmatrix} 1 & 2 & \ldots & 2^{n - 1}\end{pmatrix} \begin{pmatrix} a_0 \\ a_1 \\ \vdots \\ a_{n - 1} \end{pmatrix} \,.
\end{align*}
Since a single value $x$ is represented in multiple \enquote{units} (here: digits of a binary number), we call this kind of coding scheme a \emph{distributed} representation.

\Note{A precise definition of \emph{linearity} is provided in the notes for Lecture 2.

We could imagine using such a binary coding scheme in the context of a neural network. In a population of $n$ neurons, each neuron $i$ would represent one binary digit. However, there are several problems with this approach.
\begin{itemize}
	\item Individual units represent vastly different magnitudes. Since biological neural networks are noisy and we are using a linear decoding scheme, noise in the unit representing the digit $i = 8$ is amplified by a factor of $256$ compared to noise in the unit representing the digit $i = 0$.
	\item We assume that our units can only have two possible values, zero and one, whereas neural units can have graded responses (cf.~the response curve $G[J]$).
	\item The encoding function is complicated and there is no neurophysiological evidence that brains use a binary coding schemes.
\end{itemize}}

\subsection{Lossy Codes}

In contrast to lossless codes, lossy codes have no perfect inverse $f^{-1}$. Instead, we have a decoding function $g$ that \emph{approximates} the original value. Mathematically, we have
\begin{align*}
	\vec a &= f(\vec x) \,, && \text{Lossy Encoding} \\
	\vec x &\approx g(\vec a) = g(f(\vec x)) \,. && \text{Lossy Decoding} 
\end{align*}

\paragraph{Examples of lossy codes} In mathematics and engineering, examples of such lossy codes include Principal Component Analysis (PCA; nonlinearly reduces a dataset onto its first $n$ principal basis vectors), and coding schemes for audio and images, such as MP3 and JPEG (these coding schemes are based on the Discrete Cosine Transformation).

\Aside{Surprisingly, the Discrete Cosine Transformation (DCT) turns out to be a close to optimal \emph{linear} transformation for the compression of natural signals. When computing the PCA of a large corpus of natural images or audio (which optimally ensures that the most variance in the data is explained by the first dimensions), the resulting transformation is very similar to the DCT. However, the DCT of a signal $\vec x$ can be computed more efficiently (in $\mathcal{O}(d \log(d))$) compared to a general linear transformation (in $\mathcal{O}(d^2)$).}

\section{Neural Representation}

As discussed in the introduction, there are some neuron populations in the brain that directly represent information about stimuli in the environment. In order to better understand these representations, we first have a look at so called \emph{tuning curves}, mappings between external stimuli and the neural activity.

After looking at some real-world data, we combine our observations into a general encoding equation that captures as many properties of tuning curves as possible.

\Note{The coding scheme we are using for neural representation is both \emph{distributed} and (in practice) \emph{lossy}. In contrast to binary coding, our distributed coding scheme is more resilient to noise in the neural activities $\vec a$. Lossyness mostly stems from neurons having a limited dynamic range (saturation effects) and -- although this is not an inherent problem of the coding scheme itself -- noise in the neural system.}

\subsection{Neural Tuning Curves}

\begin{figure}[p]
	\begin{subfigure}[b]{0.5\textwidth}%
		\centering%
		\includegraphics{media/audition_tuning_curves_annotated.pdf}%
		\caption{Neural tuning curves for auditory processing}%
		\label{fig:audition_tuning_curves_annotated}%
	\end{subfigure}
	\begin{subfigure}[b]{0.5\textwidth}%
		\centering%
		\includegraphics[width=\textwidth]{media/eliasmith_et_al_2003_orientation_tuning.pdf}%
		\caption{Visual orientation tuning in V1.}
		\label{fig:eliasmith_et_al_2003_orientation_tuning}
	\end{subfigure}
	\caption{\textbf{(a)} Neural firing rates in different brain regions involved in auditory processing as a function of sound intensity in cats. Figure adapted from \cite{mann1997nervous} (Chapter 8), data from \cite{katsuki1969neural}. \CodeLink[Code used to plot the data]{lecture_03/media/code/audition.ipynb}. \textbf{(b)} Example of visual orientation tuning of a cell in primary visual cortex of a macaque monkey. Figure copied from \cite{eliasmith2003neural}, fig.~3.1.}
	\label{fig:tuning_curves_1}
\end{figure}

\begin{figure}[p]
	\hspace{0.5cm}
	\begin{subfigure}[b]{0.25\textwidth}%
		\centering%
		\hspace{-1cm}\includegraphics[scale=1.4]{media/saleem_et_al_tuning_curves_a.pdf}%
		\caption{}%
		\label{fig:saleem_et_al_tuning_curves_a}%
	\end{subfigure}%
	\begin{subfigure}[b]{0.25\textwidth}%
		\centering%
		\hspace{-1cm}\includegraphics[scale=1.4]{media/saleem_et_al_tuning_curves_b.pdf}%
		\caption{}%
		\label{fig:saleem_et_al_tuning_curves_b}%
	\end{subfigure}%
	\begin{subfigure}[b]{0.25\textwidth}%
		\centering%
		\hspace{-1cm}\includegraphics[scale=1.4]{media/saleem_et_al_tuning_curves_c.pdf}%
		\caption{}%
		\label{fig:saleem_et_al_tuning_curves_c}%
	\end{subfigure}%
	\begin{subfigure}[b]{0.25\textwidth}%
		\centering%
		\hspace{-1cm}\includegraphics[scale=1.4]{media/saleem_et_al_tuning_curves_d.pdf}%
		\caption{}%
		\label{fig:saleem_et_al_tuning_curves_d}%
	\end{subfigure}%
	\caption{Tuning curves of individual neurons in visual cortex (layer V1) for mice running in the dark. \textbf{(a-c)} Neural firing rates over the running speed of the mouse. \textbf{(d)} Histogram over tuning curve types. Figures copied from \cite{saleem2013integration}.}
	\label{fig:tuning_curves_2}
\end{figure}

In the last lecture, we have discussed neural \emph{response curves}. Response curves are a mapping between the current $J$ injected into a neuron and the corresponding neural activities. \emph{Tuning curves} are a similar concept. However, instead of plotting the current $J$ over the neural response, we plot some varying (external) stimulus over the neural response. \Cref{fig:tuning_curves_1,fig:tuning_curves_2} depict neural tuning curves as found in the neuroscience literature.

\Note{Tuning curves and \emph{internal} stimuli. Neuroscientists usually define tuning curves as the relationship between an \emph{external} stimulus and the neural response. In the NEF we extend this concept towards internal stimuli, i.e.,~neurons representing purely internal states, such as short-term memory. The lack of such tuning curves in the literature may be purely attributed to it being very hard to experimentally capture these relationships.}

Overall, we can qualitatively distinguish between three types of tuning curves (cf.~\cref{fig:saleem_et_al_tuning_curves_d})
\begin{enumerate}[i.]
	\item Responses that \emph{increase} with the intensity of the stimulus (stimulus and neural response are positively correlated; cf.~\cref{fig:audition_tuning_curves_annotated,fig:saleem_et_al_tuning_curves_a}).
	\item Responses that \emph{decrease} with the intensity of the stimulus (stimulus and neural response are negatively correlated; cf.~\cref{fig:saleem_et_al_tuning_curves_c}).
	\item Responses that have a \emph{preferred stimulus}; their response is maximal if the stimulus has a certain value and decreases if the value deviates from that value (cf.~\cref{fig:saleem_et_al_tuning_curves_b,fig:eliasmith_et_al_2003_orientation_tuning}).
\end{enumerate}

We can easily generate tuning curves of type \emph{i.}~can be easily explained by rescaling and offsetting the neural input current $J$ to match the data. In other words, we have a simple current translation function that converts the stimulus $x$ into a current $J$ that is being injected into the $i$-th neuron of our population:
\begin{align}
	J_i(x) &= \alpha_i x + J^\mathrm{bias}_i \,,
	\label{eqn:current_translation_scalar}
\end{align}
where $\alpha_i$ is the so called \emph{gain factor} and $J^\mathrm{bias}_i$ is the \emph{bias}. These parameters are describe the parameters of individual neurons in a neuron population; they are \emph{different} for each neuron in the population. Tuning curves of type \emph{ii.}~can be generated by choosing a negative gain $\alpha$. You can try to find parameters that qualitatively match the tuning curves in \cref{fig:tuning_curves_1,fig:tuning_curves_2} by playing around with the gain and offset parameters in \CodeLink[this Jupyter Notebook]{lecture_03/media/code/tuning_curve_experiments.ipynb}.

This leaves us with tuning curves of type \emph{iii.}, i.e.~tuning curves having a preferred value. We generate this problem by extending the current translation function \cref{eqn:current_translation_scalar} to accepting vectorial quantities as input.

\subsection{The Encoding Equation}

In order to generate tuning curves that qualitatively match all types of tuning curves we have seen above, we let our value $\vec x$ be a $d$-dimensional vector. The dimensionality of the represented value $d$ is specific to each neuron population. We can then choose the dot product as a measure of similarity (see note below):
\begin{align*}
	J_i(\vec x) &= \alpha_i \langle \vec x, \vec e_i \rangle + J^\mathrm{bias}_i \,,
\end{align*}
where $\alpha_i$, $J^\mathrm{bias}_i$ are the gain and bias terms for the $i$-th neuron in the population, $\vec e_i \in \mathbb{R}^d$ is the neuron's encoding -- or \enquote{preferred direction vector}, and $\langle \cdot, \cdot \rangle$ denotes the dot product between two vectors. Note that $\vec e_i$ is always normalised to unit length, that is $\|\vec e_i\| = 1$.

\Note{The \emph{dot product} (also: inner product, scalar product) $\langle \vec x, \vec y \rangle$ of two vectors $\vec x, \vec y \in \mathbb{R}^d$ is defined as
	\begin{align*}
	\langle \vec x, \vec y \rangle &= \sum_{i = 0}^d x_i y_i \,.
	\end{align*}
	We implicitly treat all vectors as column vectors; a vector $\vec x \in \mathbb{R}^d$ is implicitly a $d \times 1$ matrix (i.e., a matrix of $d$ rows and a single column). Hence, by the definition of matrix multiplication, the dot product is also given as
	\begin{align*}
	\langle \vec x, \vec y \rangle &= \vec x^\T \vec y  \quad \text{(matrix dimensions: $(1 \times d) \times (d \times 1) \rightarrow (1 \times 1)$)}\,.
	\end{align*}
	In particular, note that the dot product can be interpreted as a vector similarity measure. Namely, according to the Euclidean dot product formula
	\begin{align*}
	\langle \vec x, \vec y \rangle &= \cos(\angle(\vec x, \vec y)) \| \vec x\| \| \vec y\| \,,
	\end{align*}
	where $\| \cdot \|$ denotes the standard $L_2$-norm, and $\angle(\cdot, \cdot)$ is the angle inscribed between two vectors. Hence, the dot product is maximal if the angle between the two vectors is zero (they are pointing in the same direction, the cosine is $+1$) and zero if the two vectors are orthogonal. It is minimal (the cosine is $-1$) if the two vectors are pointing in exactly opposite directions.}

Combining the current $J_i(\vec x)$ with the neuron response curve $G[J]$ (where, again, $G$ is specific to each neuron population) yields the encoding equation:
\begin{ImportantEqn}{Encoding Equation}
	a_i(\vec x) &= G\big[J_i(\vec x)\big] = G\big[\alpha_i \langle \vec x, \vec e_i \rangle + J^\mathrm{bias}_i\big] \,.
	\label{eqn:encoding}
\end{ImportantEqn}

\paragraph{Example: 1D Encoder}
In the case of a one-dimensional encoder, the encoding \enquote{vector} can either be $+1$ or $-1$. This corresponds to o neurons that are either more active in the presence of a stimulus (positive encoder), or neurons that are more active in the absence of a stimulus (negative encoder).

\begin{figure}
	\begin{subfigure}{0.5\textwidth}
		\centering
		\includegraphics[trim=1cm 0 0 1cm,clip]{media/2d_encoder_tuning_curve.pdf}
		\caption{2D neuron tuning curve}
		\label{fig:2d_encoder_tuning_curve}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\centering
		\includegraphics{media/2d_encoder_tuning_curve_unit.pdf}
		\caption{1D projection along the unit circle}
		\label{fig:2d_encoder_tuning_curve_unit}
	\end{subfigure}
	\caption{2D neuron tuning curve for the encoding vector $\vec e = (1/\sqrt{2}, 1/\sqrt{2})$. \textbf{(a)} 3D surface plot of the 2D neuron tuning curve. Axes correspond to the magnitude of the first two components of the represented value $\vec x = (x_1, x_2)$. Orange arrow corresponds to the encoding vector. Dotted line corresponds to the unit circle. \textbf{(b)} Neural activity along the unit circle is qualitatively similar to the bell-shaped tuning curves observed in biology. \CodeLink{lecture_03/media/code/2d_encoder.ipynb}}
\end{figure}

\paragraph{Example: 2D Encoder}
\Cref{fig:2d_encoder_tuning_curve_unit} shows a tuning curve in a 2D representational space. Note that moving along the unit-circle in 2D-space generates the \enquote{preferred direction} tuning curve type observed in nature.

\section{Decoding Represented values}

As we have seen in the binary coding example above, some codes possess a \enquote{complex}, non-linear encoding scheme, but can be decoded using a simple linear decoder. Neuroscientists have similarly found that they can use a simple linear decoding scheme to extract represented values from neural populations -- we will later discuss some more examples.

In general, having a linear decoder means that we can estimate the value $\hat{\vec x}$ represented by a neural population by multiplying its current activity $\vec a$ with a decoding matrix $\mat D$:
\begin{align*}
	(\vec a)_i &=
		G\big[\alpha_i \langle \vec x, \vec e_i \rangle + J^\mathrm{bias}_i\big] \,, && \text{Encoding} \\
	\hat{\vec x} &= \mat D \vec a \,. && \text{Decoding}
\end{align*}

In the special case of a population representing a scalar value (i.e.,~the represented dimensionality $d = 1$) we have
\begin{align*}
(\vec a)_i &=
G\big[\alpha_i \langle x, e_i \rangle + J^\mathrm{bias}_i\big] \,, && \text{Encoding} \\
\hat{x} &= \langle \vec d, \vec a \rangle = \sum_{i = 1}^n d_i a_i \,. && \text{Decoding}
\end{align*}

Now that we now how to decode the represented value $\vec x$ \emph{in principle}, we of course have to somehow compute these decoders.


\subsection{Computing Identity Decoders}

In order to compute the decoders, we first have to think about what the decoders should optimally do. The roles of the decoders is to estimate the represented value and in the optimal case we would like the decoded value $\hat{\vec x}$ to be equal to or as close as possible to the encoded value $\vec x$. That is, in general we would like to minimize the error $E$ (also called a \emph{loss function})
\begin{align}
	\arg\min_{\mat D} E = \int_{\mathbb{X}} \|\vec x - \hat{\vec x}\| \,\mathrm{d}\vec x = \int_{\mathbb{X}} \|\vec x - \mat D \vec a(\vec x)\| \,\mathrm{d}\vec x \,,
	\label{eqn:optimisation_problem}
\end{align}
where $\mathbb{X}$ is a compact subspace of the possible represented values in $\mathbb{R}^d$ we are interested in.

\Note{The dynamic range of a neural representation is limited due to neural saturation and noise -- it is not possible to represent all real numbers in a single neuron population. This is why we are using this \enquote{weird} integral over a subspace $\mathbb{X}$ -- we must restrict ourselves to a range of numbers we want to be able to decode well.
	
The quantifier \emph{compact} is just a mathematical technicality that ensures that $\mathbb{X}$ is actually a \enquote{closed range} we can integrate over, and not just individual vectors picked from $\mathbb{R}^d$.}

\paragraph{Mathematical derivation} In order to make the math a little more digestible, assume that we want to find the decoders for scalar represented values ($d = 1$) and that the represented values we are interested in are over the interval $\mathbb{X} = [-1, 1]$. The above equation becomes
\begin{align}
	\arg\min_{\vec d} E
		&= \arg\min_{\vec d} \sqrt{ \int_{-1}^1 \left(x - \langle \vec d, \vec a(x) \rangle\right)^2 } \,\mathrm{d}x \\
		&= \arg\min_{\vec d} \frac{1}2 \int_{-1}^1 \left(x - \sum_{i = 1}^n d_i a_i(x) \right)^2 \,\mathrm{d}x \,.
	\label{eqn:decoder_loss}
\end{align}
This equality holds because eliminating the square root and adding a factor $\frac{1}2$ does not change the location of the minimum. Since this is a quadratic equation we know that there is exactly one extremum. In this particular case we also know that this extremum must be a minimum (since the quadratic term has a positive sign). Hence, we can find the $\vec d$ that minimizes the error by differentiating with respect to individual $d_i$ and setting the derivative to zero:
\begin{align*}
	\frac{\partial E}{\partial d_i}
		&= \frac{1}2 \int_{-1}^1 2 \left(x - \sum_{j = 1}^n d_j a_j(x) \right) \left(-a_i(x) \right) \,\mathrm{d}x
		 = \int_{-1}^1 \sum_{j = 1}^n a_j(x) d_j a_i(x) \,\mathrm{d}x - \int_{-1}^1 a_i(x) x \,\mathrm{d}x
		\overset{!}= 0 \,.
\end{align*}
Rearranging yields the following equality at $\frac{\partial E}{\partial d_i} = 0$:
\begin{align*}
	\int_{-1}^1 a_i(x) x \,\mathrm{d}x
		&= \int_{-1}^1 \sum_{j = 1}^n a_j(x) d_j a_i(x) \,\mathrm{d}x
		 = \sum_{j = 1}^n d_j \left( \int_{-1}^1 a_j(x) a_i(x) \,\mathrm{d}x \right) \,.
\end{align*}
Upon closer inspection we see that this is a system of $n$ linear equations over $\vec d = (d_1, \ldots, d_n)$. Hence, we can write this in matrix notation as $\mat\Upsilon = \mat\Gamma \vec d$, where
\begin{align*}
	\left( \mat\Upsilon \right)_i
		&= \int_{-1}^1 a_i(x) x \,\mathrm{d}x \,, &
	\left( \mat\Gamma \right)_{ij}
		 = \int_{-1}^1 a_j(x) a_i(x) \,\mathrm{d}x \,.
\end{align*}
Further evaluation of the integrals is -- generally speaking -- not possible in closed form. What we can do however is to approximate the integrals by (randomly) sampling. We pick $N$ sample points $x_1, \ldots, x_N$. Then, the above equations becomes (approximately)
\begin{align*}
	\frac{1}N \sum_{k = 1}^N a_i(x_k) x_k
		&= \frac{1}N \sum_{j = 1}^n d_j \sum_{k = 1}^N a_j(x_k) a_i(x_k) \,.
\end{align*}
The factor $1/N$ accounting for the discretisation of the integral cancels out. In matrix notation, letting $(\mat A)_{ik} = a_i(x_k)$ and $\vec \xi = (x_1, \ldots, x_k)$ we get
\begin{align*}
	\vec d &=\mat \Gamma^{-1} \mat \Upsilon \approx  (\mat A \mat A^T)^{-1} \mat A \vec \xi^\T \,, &&
	\text{where } \mat \Upsilon \approx \mat A \vec \xi \text{ and } \mat \Gamma \approx \mat A \mat A^\T \,.
\end{align*}

In general, solving \cref{eqn:optimisation_problem} directly without assuming $d = 1$ and $\mathbb{X} = [-1, 1]$, we get
\begin{ImportantEqn}{Computing decoders without taking noise into account}
	\mat D^\T &\approx  (\mat A \mat A^T)^{-1} \mat A \mat X^\T \,.
	\label{eqn:decoders}
\end{ImportantEqn}
Here, $A = \big(\vec a(\vec x_1), \ldots \vec{(\vec x_N)}\big)$ is a matrix containing the population activities as column vectors for each sample ${\vec x}_k$. $\mat X = ({\vec x}_1, \ldots, {\vec x}_k)$ is a matrix containing each input sample as a column vector.

\begin{figure}
	\centering
	\includegraphics{media/decoding_example_no_noise.pdf}
	\caption{Example of decoding the represented values from a population of neurons. \emph{Left:} Tuning curves for a population of ten neurons. Tuning curves were chosen such that the $x$-intercepts of the tuning curves are sampled from a uniform distribution over the interval $[-1, 1]$. The maximum firing rate over that interval is uniformly sampled from $[100, 200]$. Neuron encoders were randomly selected to be either $+1$ or $-1$. \emph{Middle:} Represented value and the decoded value on the same plot. \emph{Right:} Decoding error $\hat x - x$. \CodeLink{lecture_03/media/code/computing_decoders.ipynb}}
	\label{fig:decoding_example_no_noise}
\end{figure}

To summarize, in order to solve for decoders we first randomly sample a set of $N$ values $\mat X = ({\vec x}_1, \ldots, {\vec x}_k)$ we would like to represent. Using the encoding equation in \cref{eqn:encoding} we then compute what the population activities would be for each of these samples, giving us $A = \big(\vec a(\vec x_1), \ldots \vec{(\vec x_N)}\big)$. We then plug these matrices into \cref{eqn:decoders}, giving us the decoding matrix $\mat D$. \Cref{fig:decoding_example_no_noise} shows an example depicting the overall encoding and decoding process.

\Note{\emph{Least squares.}
The problem we just solved is a \emph{linear least squares optimisation problem}, and the solution given in \cref{eqn:decoders} has been independently discovered in the early 19th century by the mathematicians Adrien-Marie Legendre and Carl Friedrich Gauss.}

\Note{\emph{Moore-Penrose Pseudo Inverse.}
The term \enquote{$(\mat A \mat A^T)^{-1} \mat A$} is also called Moore-Penrose Pseudo Inverse of a matrix $\mat A$. It is sometimes written as $\mat A^+$. The name \enquote{Pseudo Inverse} stems from the fact that it performs an inverse-like operation for non-square matrices.}

\cprotect\Python{In Python, you can solve the above linear least-squares problem using the following code:
\begin{lstlisting}[language=python]
import numpy as np
A = np.array(...) # n x N array
X = np.array(...) # d x N array
D = np.linalg.lstsq(A.T, X.T, rcond=None)[0].T
\end{lstlisting}
Have a look at the \href{https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html}{documentation of \texttt{lstsq}} for a precise description of its behaviour.}

\subsection{Sources of Noise in Neural Systems}

We now know how to compute linear decoders $\mat D$ that estimate the value represented by an ensemble of neurons. However, we implicitly made the assumption that each neuron perfectly implements its response curve $G[J]$. We know that this is not true in biological systems.

\paragraph{Noise due to spike rate estimation errors}
The response curve $G[J]$ is only a first-order approximation of a neuron's behaviour. We know that in real biological systems neurons communicate using spikes -- and it is impossible to perfectly estimate it's firing rate over a short time window (cf.~the time and frequency uncertainty principle \cite{gabor1946theory}). This measurement error can be interpreted as \emph{noise}.

\paragraph{Biological sources of error}
Nervous systems contain various sources of error, including, but not limited to the following (cf.~\cite{gerstner2002spiking}, Chapter 5.1)
\begin{itemize}
	\item \textbf{Axonal jitter.}
	The action potential transmission speed varies between spikes. This is because action potentials are transported \emph{actively}, i.e.,~they do not travel along the axon due to passive electrical properties of the axon but are constantly renewed at the so called \enquote{Nodes of Ranvier}.
	\item \textbf{Neurotransmitter vesicle release failure.}
	Only 10-30\% of pre-synaptic spikes generate a post-synaptic event -- one reason being that the release of neurotransmitter vesicles is stochastic.
	\item \textbf{Amount of neurotransmitter per vesicle.}
	The amount of neurotransmitters in a vesicle varies between vesicles. The intensity of the post-synaptic response depends on the specific vesicle that releases neurotransmitter into the synaptic cleft.
	\item \textbf{Ion channel noise.}
	The excitatory and inhibitory post-synaptic currents are generated by ion-channels in the neuron's cell membrane opening and closing in response to receiving neuro transmitters. These ion-channels are binary: they can either be fully open or fully closed. The graded nature of post-synaptic currents stems from the fact that many ion-channels open and close in a stochastic fashion.
	\item \textbf{Thermal noise.}
	In general, on the level of molecular biology many processes rely on thermal noise to be triggered -- this can be seen as an explanation of the noisiness of the above processes.
	\item \textbf{Network effects.}
	Even simple, non-noisy recurrent networks of excitatory and inhibitory spiking neurons can produce highly irregular spike patterns.
\end{itemize}

Given these considerations, we should add a zeroth principle to the NEF:\footnote{In the text this principle is called an \enquote{addendum} and listed as the fourth principle. I think that this principle is so fundamental that it should be number zero in the list.}
\begin{mdframed}
	\textbf{NEF Principle 0 -- Noise}\\
	Biological neural systems are subject to significant amounts of noise from various sources. Any analysis of such systems must take the effects of noise into account.
\end{mdframed}

\begin{figure}
	\centering
	\includegraphics{media/decoding_example_noise.pdf}
	\caption{Decoding the represented value from a population of neurons with added noise (Gaussian, $\mu = 0$, $\sigma = 0.1 \max(A)$). See \cref{fig:decoding_example_no_noise} for the complete description. \CodeLink{lecture_03/media/code/computing_decoders.ipynb}}
	\label{fig:decoding_example_noise}
\end{figure}


\paragraph{Modelling Noise}
To test whether our modelling framework still holds when we take noise into account, we should somehow be able to include noise to our models. There are two potential ways how we can accomplish this. Either we add more detail to our neuron models and simulate the noise sources, or we -- for now -- simply add noise from a distribution to our neural activities $\vec a$.

\Cref{fig:decoding_example_noise} depicts the decoding accuracy when adding Gaussian noise to the neural activities. As clearly visible, our current method for computing the decoders is incapable of properly dealing with this noise.\footnote{To be fair, the example depicted in \cref{fig:decoding_example_noise} has been consciously chosen to be close to a worst-case scenario.} Can we do better? Let's go back to the drawing board and do some more math.

\subsection{Computing Decoders Taking Noise Into Account}

The formula for computing the decoders given in \cref{eqn:decoders} has three problems.
\begin{enumerate}[1.]
	\item As discussed above, neural activities are always noisy (see discussion above) -- we did not account for this in our derivation of \cref{eqn:decoders}.
	\item From a mathematical perspective, $\mat A \mat A^\T$ may not always be invertible -- this may happen if individual rows/columns in $\mat A$ are linearly dependent.
	\item From a numerics perspective, even if $\mat A \mat A^\T$ happens to be invertible (in a mathematical sense), doing so may be numerically instable if individual rows/columns in $\mat A$ are almost linearly dependent. This may happen if some neurons have approximately the same parameters.
\end{enumerate}
Interestingly, addressing the first problem, i.e.,~taking noise into account when deriving \cref{eqn:decoders}, will magically solve the other two problems.

\paragraph{Mathematical derivation}
Again, we derive the math under the assumption that $d = 1$ (i.e.,~we are representing scalar values), but the result can be easily generalised to multiple dimensions.

Furthermore, we assume that there is independent noise sampled from a Gaussian distribution with mean zero and a standard deviation $\sigma$ superimposed onto each neural activitiy. That is, whenever we try to measure the neural activity of neuron $i$ for an input $x$, we really get a value $a_i(\vec x) + \eta$, where $\eta$ is a random variable that has been sampled from $\mathcal{N}(0, \sigma^2)$.

Plugging this into our derivation from above and minimizing the expectation value $\mathbb{E}$, we get
\begin{align*}
	\arg\min_{\vec d} E
		&= \arg\min_{\vec d} \mathbb{E} \left[ \frac{1}2 \int_{-1}^1 \left(x - \sum_{i = 1}^n d_i \big(a_i(x) + \eta\big) \right)^2 \,\mathrm{d}x \right]_\eta &&\text{where } \eta \sim \mathcal{N}(0, \sigma^2) \\
		&= \arg\min_{\vec d} \mathbb{E} \left[
			\int_{-1}^1 \left(x - \sum_{i = 1}^n d_i a_i(x) - \sum_{i = 1}^n d_i \eta\big) \right)^2 \,\mathrm{d}x \right]_\eta  \\
		&= \arg\min_{\vec d} \frac{1}2 
			\int_{-1}^1 \left(x - \sum_{i = 1}^n d_i a_i(x) \right)^2 \,\mathrm{d}x
			+ \sum_{i = 1}^n \sum_{j = 1}^n d_i d_j \mathbb{E} \left[ \eta_i \eta_j \right]_{\eta_i, \eta_j}
\end{align*}
Note that the cross-terms in the above double-sum disappear: the expectation value of the product between two independent, mean zero random variables is zero. We get
\begin{align*}
	\arg\min_{\vec d} E
		&= \arg\min_{\vec d} \frac{1}2 
		\int_{-1}^1 \left(x - \sum_{i = 1}^n d_i a_i(x) \right)^2 \,\mathrm{d}x
		+ \sum_{i = 1}^n d_i^2 \mathbb{E} \left[ \eta_i^2 \right]_{\eta_i}
\end{align*}
Since the mean of the distribution is zero, the remaining expectation value is exactly the variance of $\eta$:
\begin{align}
\arg\min_{\vec d} E
	&= \arg\min_{\vec d} \frac{1}2 
	\int_{-1}^1 \left(x - \sum_{i = 1}^n d_i a_i(x) \right)^2 \,\mathrm{d}x
	+ \sigma^2 \sum_{i = 1}^n d_i^2 \,.
	\label{eqn:decoder_loss_regularised}
\end{align}
\Note{\emph{Equivalence of \enquote{taking Gaussian noise into account} and $L_2$-regularisation.} \Cref{eqn:decoder_loss_regularised} can be interpreted in a different, but extremely useful manner. Essentially, our error expression is exactly the same as when we set out to derive this equation without noise, cf.~\cref{eqn:decoder_loss}. The difference is that we penalize the magnitude of the coefficients $d_i$: the larger $|d_i|$, the larger the error $E$ will be.

Adding such a weight penalisation term is commonly referred to as \emph{regularisation}. Generally, $L_\ell$-regularisation (where $\ell$ is a positive number, usually one or two) adds the following loss term to $E$:
\begin{align*}
	\lambda \sum_{i = 1}^n |d_i|^\ell \,,
\end{align*}
where $\lambda$ is the so called \enquote{regularisation factor}. Hence, in the case above, we are using $L_2$ regularisation with $\lambda = \sigma^2$.

The effect of regularisation is the following: when solving for $\vec d$, we try to balance between minimizing the error and not having large decoder coefficients $d_i^2$. Since the coefficients are being squared, the optimal solution will be small, non-zero decoder coefficients that effectively \enquote{average} over the activities from multiple neurons. This averaging is also able to reduce the impact of noise on the activities.}

\begin{figure}
	\centering
	\includegraphics{media/decoding_example_noise_accounted.pdf}
	\caption{Decoding the represented value from a population of neurons with added noise (Gaussian, $\mu = 0$, $\sigma = 0.2 \max(A)$) while accounting for noise. See \cref{fig:decoding_example_no_noise} for the complete description. \CodeLink{lecture_03/media/code/computing_decoders.ipynb}}
	\label{fig:decoding_example_noise_accounted}
\end{figure}

We can now continue to solve for $\vec{d}$ as above. After some linear algebra, we arrive at the following equation (here, directly for arbitrary represented dimensions $d \geq 1$)
\begin{ImportantEqn}{Computing decoders taking noise into account}
	\mat D^\T &\approx  \left(\frac{1}{N} \mat A \mat A^\T + \sigma^2 \mat I\right)^{-1} \mat A \mat X^\T \,, \text{ where $\mat I$ is the $n \times n$ identity matrix}
	\label{eqn:decoders_noise}
\end{ImportantEqn}
Adding a scaled version of the identity matrix to $\mat A \mat A^T$ ensures that the resulting matrix is always invertible. If $\sigma^2$ is large enough, this inversion is possible in a numerically stable way. As visible in \cref{fig:decoding_example_noise_accounted}, the decoding error is now in an acceptable range, even if we add noise to the pre-population.

\cprotect\Python{In Python, you can solve the above regularised linear least-squares problem using the following code:
\begin{lstlisting}[language=python]
import numpy as np
A = np.array(...) # n x N array
X = np.array(...) # d x N array
D = np.linalg.lstsq(
        A @ A.T / N + np.square(sigma) * np.eye(n), A @ X.T,
        rcond=None)[0].T
\end{lstlisting}
Using \texttt{lstsq} is numerically more stable than manually inverting the matrix using a function such as \texttt{np.linalg.inv}.}

%\subsection{Analysing Sources of Error}

%\section{Examples}
%
%\subsection{Horizontal Eye Control (1D)}
%
%\subsection{Arm Movements (2D)}
%
%\subsection{Higher-dimensional Tuning}

\printbibliography

\end{document}
